{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install textstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5l49keQckUy",
        "outputId": "21dcd3ee-d3a4-4464-d6fb-da895abe8c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textstat\n",
            "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.15.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.15.0 textstat-0.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "import spacy\n",
        "from textstat.textstat import textstatistics\n"
      ],
      "metadata": {
        "id": "2G0vk74-cW4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "    # Tokenize into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "    # Tokenize into words\n",
        "    words = [word_tokenize(sentence) for sentence in sentences]\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [[word for word in word_list if word not in stop_words] for word_list in words]\n",
        "    return filtered_words\n"
      ],
      "metadata": {
        "id": "_yQSAGL7cYCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_keywords(text):\n",
        "    # Assume preprocess_text has been called first\n",
        "    processed_text = preprocess_text(text)\n",
        "    # Flatten the list of lists\n",
        "    all_words = [word for sublist in processed_text for word in sublist]\n",
        "    # Frequency distribution\n",
        "    freq_dist = nltk.FreqDist(all_words)\n",
        "    keywords = [word for word, freq in freq_dist.items() if freq > 1]\n",
        "    return keywords\n"
      ],
      "metadata": {
        "id": "AsELYujrcygC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def topic_modeling(text):\n",
        "    processed_text = preprocess_text(text)\n",
        "    dictionary = corpora.Dictionary(processed_text)\n",
        "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in processed_text]\n",
        "    lda_model = LdaModel(doc_term_matrix, num_topics=5, id2word=dictionary, passes=25)  # Adjust num_topics and passes as needed\n",
        "    topics = lda_model.print_topics(num_words=3)  # Adjust num_words as needed\n",
        "    return topics\n"
      ],
      "metadata": {
        "id": "HA6dvnEIc0Kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def named_entity_recognition(text):\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    doc = nlp(text)\n",
        "    entities = [(entity.text, entity.label_) for entity in doc.ents]\n",
        "    return entities\n"
      ],
      "metadata": {
        "id": "SmRuX4ZRc2I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_complexity(text):\n",
        "    syllables = textstatistics().syllable_count(text)\n",
        "    sentences = textstatistics().sentence_count(text)\n",
        "    words = len(word_tokenize(text))\n",
        "    # The Flesch-Kincaid Grade Level formula\n",
        "    flesch_kincaid_grade = 0.39 * (words/sentences) + 11.8 * (syllables/words) - 15.59\n",
        "    return flesch_kincaid_grade\n"
      ],
      "metadata": {
        "id": "any7U2h6dDvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NHZ3KozdTaq",
        "outputId": "f66cae4b-d874-4070-a73f-e1edf29a6285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1co8XpA6daSP",
        "outputId": "196a76c1-cb18-495b-f247-e26c62f9e39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_text = \"\"\"[Interviewer: Can you tell us about your experience with software development especially in the context of web applications?\n",
        "\n",
        "Candidate: Absolutely I've been involved in software development for over five years now with a particular focus on web applications I've worked extensively with technologies like JavaScript React and Node.js. One of my significant projects was developing a real-time analytics dashboard for a retail client which involved complex data processing and visualization. We used React for the frontend to ensure a responsive and intuitive user interface and Node.js on the backend for its scalability and efficiency with real-time data.\n",
        "\n",
        "Interviewer: That sounds like an impressive project How did you approach the challenges that came with it?\n",
        "\n",
        "Candidate: The project had its set of challenges especially around handling large volumes of data in real-time We utilized WebSocket for real-time data communication between the server and the client For data processing and management we implemented Redis as an in-memory database to reduce latency. The entire development process was agile which allowed us to iterate quickly based on user feedback and continuously improve the application's performance and usability.\n",
        "\n",
        "Interviewer: Have you had experience with cloud technologies or containerization?\n",
        "\n",
        "Candidate: Yes indeed For several projects I've leveraged cloud services mainly AWS to enhance scalability and reliability I have experience with EC2 for virtual servers S3 for storage and Lambda for serverless functions which was particularly useful for background tasks and automations. Regarding containerization I've used Docker to create lightweight portable and consistent environments for development testing and deployment facilitating a smooth CI/CD pipeline with Jenkins.\n",
        "\n",
        "Interviewer: And how do you keep up with the rapidly changing technology landscape?\n",
        "\n",
        "Candidate: I'm a firm believer in continuous learning I regularly attend tech meetups participate in online forums and take courses on platforms like Coursera and Udemy Recently I've been diving into machine learning and AI understanding their potential applications in web development especially in personalized user experiences and predictive analytics.\n",
        "\n",
        "Interviewer: Thank you for sharing your experiences with us It's clear you have a strong foundation in software development and a proactive approach to learning and adapting to new technologies]\"\"\"\n",
        "keywords = identify_keywords(interview_text)\n",
        "print(\"Keywords:\", keywords)\n",
        "\n",
        "topics = topic_modeling(interview_text)\n",
        "print(\"Topics:\", topics)\n",
        "\n",
        "entities = named_entity_recognition(interview_text)\n",
        "print(\"Named Entities:\", entities)\n",
        "\n",
        "complexity_score = analyze_complexity(interview_text)\n",
        "print(\"Complexity Score:\", complexity_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JB0wR1-dFtN",
        "outputId": "a4b26376-5f73-46c9-9014-2ae5815f303e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keywords: ['interviewer', ':', 'us', 'experience', 'software', 'development', 'especially', 'web', 'applications', '?', 'candidate', \"'ve\", 'involved', 'technologies', 'like', 'react', 'node.js', '.', 'projects', 'real-time', 'analytics', 'client', 'data', 'processing', 'used', 'user', 'scalability', 'project', 'approach', 'challenges', \"'s\", 'cloud', 'containerization', 'learning', 'experiences']\n",
            "Topics: [(0, '0.035*\"development\" + 0.024*\"experience\" + 0.024*\"us\"'), (1, '0.026*\"user\" + 0.026*\"learning\" + 0.026*\".\"'), (2, '0.040*\"\\'ve\" + 0.022*\"technologies\" + 0.022*\"software\"'), (3, '0.039*\"data\" + 0.030*\"real-time\" + 0.030*\".\"'), (4, '0.046*\":\" + 0.046*\"interviewer\" + 0.031*\"?\"')]\n",
            "Named Entities: [('five years', 'DATE'), ('JavaScript React', 'ORG'), ('One', 'CARDINAL'), ('Node.js', 'ORG'), ('WebSocket', 'ORG'), ('AWS', 'ORG'), ('S3', 'CARDINAL'), ('Lambda', 'NORP'), ('Docker', 'PERSON'), ('CI', 'PERSON'), ('Jenkins', 'PERSON'), ('Coursera', 'PERSON'), ('Udemy', 'PERSON'), ('AI', 'ORG')]\n",
            "Complexity Score: 15.50591756807162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install spacy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of4fDP0_SHjL",
        "outputId": "aae771c0-1c01-4367-e260-30cdce0d0756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def dependency_parsing(text):\n",
        "    # Process the text with SpaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Iterate over the sentences in the document\n",
        "    for sentence in doc.sents:\n",
        "        print(f\"Sentence: {sentence.text}\\n\")\n",
        "        # Iterate over each token in the sentence\n",
        "        for token in sentence:\n",
        "            print(f\"{token.text:<12} {token.dep_:<10} {token.head.text:<12} {token.head.pos_:<6} {spacy.explain(token.dep_)}\")\n",
        "        print(\"\\n---\\n\")\n",
        "\n",
        "# Example text\n",
        "example_text = \"\"\"Interviewer: Can you tell us about your experience with software development especially in the context of web applications?\n",
        "\n",
        "Candidate: Absolutely I've been involved in software development for over five years now with a particular focus on web applications I've worked extensively with technologies like JavaScript React and Node.js. One of my significant projects was developing a real-time analytics dashboard for a retail client which involved complex data processing and visualization. We used React for the frontend to ensure a responsive and intuitive user interface and Node.js on the backend for its scalability and efficiency with real-time data.\n",
        "\n",
        "Interviewer: That sounds like an impressive project How did you approach the challenges that came with it?\n",
        "\n",
        "Candidate: The project had its set of challenges especially around handling large volumes of data in real-time We utilized WebSocket for real-time data communication between the server and the client For data processing and management we implemented Redis as an in-memory database to reduce latency. The entire development process was agile which allowed us to iterate quickly based on user feedback and continuously improve the application's performance and usability.\n",
        "\n",
        "Interviewer: Have you had experience with cloud technologies or containerization?\n",
        "\n",
        "Candidate: Yes indeed For several projects I've leveraged cloud services mainly AWS to enhance scalability and reliability I have experience with EC2 for virtual servers S3 for storage and Lambda for serverless functions which was particularly useful for background tasks and automations. Regarding containerization I've used Docker to create lightweight portable and consistent environments for development testing and deployment facilitating a smooth CI/CD pipeline with Jenkins.\n",
        "\n",
        "Interviewer: And how do you keep up with the rapidly changing technology landscape?\n",
        "\n",
        "Candidate: I'm a firm believer in continuous learning I regularly attend tech meetups participate in online forums and take courses on platforms like Coursera and Udemy Recently I've been diving into machine learning and AI understanding their potential applications in web development especially in personalized user experiences and predictive analytics.\n",
        "\n",
        "Interviewer: Thank you for sharing your experiences with us It's clear you have a strong foundation in software development and a proactive approach to learning and adapting to new technologies\"\"\"\n",
        "\n",
        "dependency_parsing(example_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37whW24BSby1",
        "outputId": "e9342ff0-8160-4cfc-cce5-19642a86908c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: Interviewer: Can you tell us about your experience with software development especially in the context of web applications?\n",
            "\n",
            "\n",
            "\n",
            "Interviewer  ROOT       Interviewer  NOUN   root\n",
            ":            punct      Interviewer  NOUN   punctuation\n",
            "Can          aux        tell         VERB   auxiliary\n",
            "you          nsubj      tell         VERB   nominal subject\n",
            "tell         acl        Interviewer  NOUN   clausal modifier of noun (adjectival clause)\n",
            "us           dobj       tell         VERB   direct object\n",
            "about        prep       tell         VERB   prepositional modifier\n",
            "your         poss       experience   NOUN   possession modifier\n",
            "experience   pobj       about        ADP    object of preposition\n",
            "with         prep       experience   NOUN   prepositional modifier\n",
            "software     compound   development  NOUN   compound\n",
            "development  pobj       with         ADP    object of preposition\n",
            "especially   advmod     in           ADP    adverbial modifier\n",
            "in           prep       tell         VERB   prepositional modifier\n",
            "the          det        context      NOUN   determiner\n",
            "context      pobj       in           ADP    object of preposition\n",
            "of           prep       context      NOUN   prepositional modifier\n",
            "web          compound   applications NOUN   compound\n",
            "applications pobj       of           ADP    object of preposition\n",
            "?            punct      tell         VERB   punctuation\n",
            "\n",
            "\n",
            "           dep        ?            PUNCT  unclassified dependent\n",
            "\n",
            "---\n",
            "\n",
            "Sentence: Candidate:\n",
            "\n",
            "Candidate    ROOT       Candidate    NOUN   root\n",
            ":            punct      Candidate    NOUN   punctuation\n",
            "\n",
            "---\n",
            "\n",
            "Sentence: Absolutely I've been involved in software development for over five years now with a particular focus on web applications I've worked extensively with technologies like JavaScript React and Node.js.\n",
            "\n",
            "Absolutely   advmod     involved     VERB   adverbial modifier\n",
            "I            nsubjpass  involved     VERB   nominal subject (passive)\n",
            "'ve          aux        involved     VERB   auxiliary\n",
            "been         auxpass    involved     VERB   auxiliary (passive)\n",
            "involved     ROOT       involved     VERB   root\n",
            "in           prep       involved     VERB   prepositional modifier\n",
            "software     compound   development  NOUN   compound\n",
            "development  pobj       in           ADP    object of preposition\n",
            "for          prep       involved     VERB   prepositional modifier\n",
            "over         quantmod   five         NUM    modifier of quantifier\n",
            "five         nummod     years        NOUN   numeric modifier\n",
            "years        pobj       for          ADP    object of preposition\n",
            "now          advmod     involved     VERB   adverbial modifier\n",
            "with         prep       involved     VERB   prepositional modifier\n",
            "a            det        focus        NOUN   determiner\n",
            "particular   amod       focus        NOUN   adjectival modifier\n",
            "focus        pobj       with         ADP    object of preposition\n",
            "on           prep       focus        NOUN   prepositional modifier\n",
            "web          compound   applications NOUN   compound\n",
            "applications pobj       on           ADP    object of preposition\n",
            "I            nsubj      worked       VERB   nominal subject\n",
            "'ve          aux        worked       VERB   auxiliary\n",
            "worked       relcl      focus        NOUN   relative clause modifier\n",
            "extensively  advmod     worked       VERB   adverbial modifier\n",
            "with         prep       worked       VERB   prepositional modifier\n",
            "technologies pobj       with         ADP    object of preposition\n",
            "like         prep       technologies NOUN   prepositional modifier\n",
            "JavaScript   compound   React        PROPN  compound\n",
            "React        pobj       like         ADP    object of preposition\n",
            "and          cc         React        PROPN  coordinating conjunction\n",
            "Node.js      conj       React        PROPN  conjunct\n",
            ".            punct      involved     VERB   punctuation\n",
            "\n",
            "---\n",
            "\n",
            "Sentence: One of my significant projects was developing a real-time analytics dashboard for a retail client which involved complex data processing and visualization.\n",
            "\n",
            "One          nsubj      developing   VERB   nominal subject\n",
            "of           prep       One          NUM    prepositional modifier\n",
            "my           poss       projects     NOUN   possession modifier\n",
            "significant  amod       projects     NOUN   adjectival modifier\n",
            "projects     pobj       of           ADP    object of preposition\n",
            "was          aux        developing   VERB   auxiliary\n",
            "developing   ROOT       developing   VERB   root\n",
            "a            det        dashboard    NOUN   determiner\n",
            "real         amod       time         NOUN   adjectival modifier\n",
            "-            punct      time         NOUN   punctuation\n",
            "time         compound   dashboard    NOUN   compound\n",
            "analytics    compound   dashboard    NOUN   compound\n",
            "dashboard    dobj       developing   VERB   direct object\n",
            "for          prep       developing   VERB   prepositional modifier\n",
            "a            det        client       NOUN   determiner\n",
            "retail       amod       client       NOUN   adjectival modifier\n",
            "client       pobj       for          ADP    object of preposition\n",
            "which        nsubj      involved     VERB   nominal subject\n",
            "involved     relcl      client       NOUN   relative clause modifier\n",
            "complex      amod       processing   NOUN   adjectival modifier\n",
            "data         compound   processing   NOUN   compound\n",
            "processing   dobj       involved     VERB   direct object\n",
            "and          cc         processing   NOUN   coordinating conjunction\n",
            "visualization conj       processing   NOUN   conjunct\n",
            ".            punct      developing   VERB   punctuation\n",
            "\n",
            "---\n",
            "\n",
            "Sentence: We used React for the frontend to ensure a responsive and intuitive user interface and Node.js on the backend for its scalability and efficiency with real-time data.\n",
            "\n",
            "Interviewer: That sounds like an impressive project How did you approach the challenges that came with it?\n",
            "\n",
            "\n",
            "\n",
            "We           nsubj      used         VERB   nominal subject\n",
            "used         ROOT       used         VERB   root\n",
            "React        dobj       used         VERB   direct object\n",
            "for          prep       used         VERB   prepositional modifier\n",
            "the          det        frontend     NOUN   determiner\n",
            "frontend     pobj       for          ADP    object of preposition\n",
            "to           aux        ensure       VERB   auxiliary\n",
            "ensure       xcomp      used         VERB   open clausal complement\n",
            "a            det        interface    NOUN   determiner\n",
            "responsive   amod       interface    NOUN   adjectival modifier\n",
            "and          cc         responsive   ADJ    coordinating conjunction\n",
            "intuitive    conj       responsive   ADJ    conjunct\n",
            "user         compound   interface    NOUN   compound\n",
            "interface    dobj       ensure       VERB   direct object\n",
            "and          cc         interface    NOUN   coordinating conjunction\n",
            "Node.js      conj       interface    NOUN   conjunct\n",
            "on           prep       ensure       VERB   prepositional modifier\n",
            "the          det        backend      NOUN   determiner\n",
            "backend      pobj       on           ADP    object of preposition\n",
            "for          prep       backend      NOUN   prepositional modifier\n",
            "its          poss       scalability  NOUN   possession modifier\n",
            "scalability  pobj       for          ADP    object of preposition\n",
            "and          cc         scalability  NOUN   coordinating conjunction\n",
            "efficiency   conj       scalability  NOUN   conjunct\n",
            "with         prep       scalability  NOUN   prepositional modifier\n",
            "real         amod       time         NOUN   adjectival modifier\n",
            "-            punct      time         NOUN   punctuation\n",
            "time         compound   data         NOUN   compound\n",
            "data         pobj       with         ADP    object of preposition\n",
            ".            punct      used         VERB   punctuation\n",
            "\n",
            "\n",
            "           dep        .            PUNCT  unclassified dependent\n",
            "Interviewer  dobj       used         VERB   direct object\n",
            ":            punct      Interviewer  PROPN  punctuation\n",
            "That         nsubj      sounds       VERB   nominal subject\n",
            "sounds       conj       used         VERB   conjunct\n",
            "like         prep       sounds       VERB   prepositional modifier\n",
            "an           det        project      NOUN   determiner\n",
            "impressive   amod       project      NOUN   adjectival modifier\n",
            "project      pobj       like         ADP    object of preposition\n",
            "How          advmod     approach     VERB   adverbial modifier\n",
            "did          aux        approach     VERB   auxiliary\n",
            "you          nsubj      approach     VERB   nominal subject\n",
            "approach     relcl      project      NOUN   relative clause modifier\n",
            "the          det        challenges   NOUN   determiner\n",
            "challenges   dobj       approach     VERB   direct object\n",
            "that         nsubj      came         VERB   nominal subject\n",
            "came         relcl      challenges   NOUN   relative clause modifier\n",
            "with         prep       came         VERB   prepositional modifier\n",
            "it           pobj       with         ADP    object of preposition\n",
            "?            punct      sounds       VERB   punctuation\n",
            "\n",
            "\n",
            "           dep        ?            PUNCT  unclassified dependent\n",
            "\n",
            "---\n",
            "\n",
            "Sentence: Candidate: The project had its set of challenges especially around handling large volumes of data in real-time We utilized WebSocket for real-time data communication between the server and the client For data processing and management we implemented Redis as an in-memory database to reduce latency.\n",
            "\n",
            "Candidate    nsubj      implemented  VERB   nominal subject\n",
            ":            punct      had          VERB   punctuation\n",
            "The          det        project      NOUN   determiner\n",
            "project      nsubj      had          VERB   nominal subject\n",
            "had          ccomp      implemented  VERB   clausal complement\n",
            "its          poss       set          NOUN   possession modifier\n",
            "set          dobj       had          VERB   direct object\n",
            "of           prep       set          NOUN   prepositional modifier\n",
            "challenges   pobj       of           ADP    object of preposition\n",
            "especially   advmod     around       ADP    adverbial modifier\n",
            "around       prep       had          VERB   prepositional modifier\n",
            "handling     pcomp      around       ADP    complement of preposition\n",
            "large        amod       volumes      NOUN   adjectival modifier\n",
            "volumes      dobj       handling     VERB   direct object\n",
            "of           prep       volumes      NOUN   prepositional modifier\n",
            "data         pobj       of           ADP    object of preposition\n",
            "in           prep       handling     VERB   prepositional modifier\n",
            "real         amod       time         NOUN   adjectival modifier\n",
            "-            punct      time         NOUN   punctuation\n",
            "time         pobj       in           ADP    object of preposition\n",
            "We           nsubj      utilized     VERB   nominal subject\n",
            "utilized     relcl      time         NOUN   relative clause modifier\n",
            "WebSocket    dobj       utilized     VERB   direct object\n",
            "for          prep       utilized     VERB   prepositional modifier\n",
            "real         amod       time         NOUN   adjectival modifier\n",
            "-            punct      time         NOUN   punctuation\n",
            "time         compound   communication NOUN   compound\n",
            "data         compound   communication NOUN   compound\n",
            "communication pobj       for          ADP    object of preposition\n",
            "between      prep       communication NOUN   prepositional modifier\n",
            "the          det        server       NOUN   determiner\n",
            "server       pobj       between      ADP    object of preposition\n",
            "and          cc         server       NOUN   coordinating conjunction\n",
            "the          det        client       NOUN   determiner\n",
            "client       conj       server       NOUN   conjunct\n",
            "For          prep       utilized     VERB   prepositional modifier\n",
            "data         compound   processing   NOUN   compound\n",
            "processing   pobj       For          ADP    object of preposition\n",
            "and          cc         processing   NOUN   coordinating conjunction\n",
            "management   conj       processing   NOUN   conjunct\n",
            "we           nsubj      implemented  VERB   nominal subject\n",
            "implemented  ROOT       implemented  VERB   root\n",
            "Redis        dobj       implemented  VERB   direct object\n",
            "as           prep       implemented  VERB   prepositional modifier\n",
            "an           det        database     NOUN   determiner\n",
            "in           nmod       database     NOUN   modifier of nominal\n",
            "-            punct      in           ADP    punctuation\n",
            "memory       pobj       in           ADP    object of preposition\n",
            "database     pobj       as           ADP    object of preposition\n",
            "to           aux        reduce       VERB   auxiliary\n",
            "reduce       advcl      implemented  VERB   adverbial clause modifier\n",
            "latency      dobj       reduce       VERB   direct object\n",
            ".            punct      implemented  VERB   punctuation\n",
            "\n",
            "---\n",
            "\n",
            "Sentence: The entire development process was agile which allowed us to iterate quickly based on user feedback and continuously improve the application's performance and usability.\n",
            "\n",
            "\n",
            "\n",
            "The          det        process      NOUN   determiner\n",
            "entire       amod       process      NOUN   adjectival modifier\n",
            "development  compound   process      NOUN   compound\n",
            "process      nsubj      was          AUX    nominal subject\n",
            "was          ROOT       was          AUX    root\n",
            "agile        acomp      was          AUX    adjectival complement\n",
            "which        nsubj      allowed      VERB   nominal subject\n",
            "allowed      advcl      was          AUX    adverbial clause modifier\n",
            "us           nsubj      iterate      VERB   nominal subject\n",
            "to           aux        iterate      VERB   auxiliary\n",
            "iterate      ccomp      allowed      VERB   clausal complement\n",
            "quickly      advmod     iterate      VERB   adverbial modifier\n",
            "based        prep       iterate      VERB   prepositional modifier\n",
            "on           prep       based        VERB   prepositional modifier\n",
            "user         compound   feedback     NOUN   compound\n",
            "feedback     pobj       on           ADP    object of preposition\n",
            "and          cc         iterate      VERB   coordinating conjunction\n",
            "continuously advmod     improve      VERB   adverbial modifier\n",
            "improve      conj       iterate      VERB   conjunct\n",
            "the          det        application  NOUN   determiner\n",
            "application  poss       performance  NOUN   possession modifier\n",
            "'s           case       application  NOUN   case marking\n",
            "performance  dobj       improve      VERB   direct object\n",
            "and          cc         performance  NOUN   coordinating conjunction\n",
            "usability    conj       performance  NOUN   conjunct\n",
            ".            punct      was          AUX    punctuation\n",
            "\n",
            "\n",
            "           dep        .            PUNCT  unclassified dependent\n",
            "\n",
            "---\n",
            "\n",
            "Sentence: Interviewer: Have you had experience with cloud technologies or containerization?\n",
            "\n",
            "\n",
            "\n",
            "Interviewer  ROOT       Interviewer  PROPN  root\n",
            ":            punct      Interviewer  PROPN  punctuation\n",
            "Have         aux        had          AUX    auxiliary\n",
            "you          nsubj      had          AUX    nominal subject\n",
            "had          acl        Interviewer  PROPN  clausal modifier of noun (adjectival clause)\n",
            "experience   dobj       had          AUX    direct object\n",
            "with         prep       experience   NOUN   prepositional modifier\n",
            "cloud        compound   technologies NOUN   compound\n",
            "technologies pobj       with         ADP    object of preposition\n",
            "or           cc         technologies NOUN   coordinating conjunction\n",
            "containerization conj       technologies NOUN   conjunct\n",
            "?            punct      had          AUX    punctuation\n",
            "\n",
            "\n",
            "           dep        ?            PUNCT  unclassified dependent\n",
            "\n",
            "---\n",
            "\n",
            "Sentence: Candidate:\n",
            "\n",
            "Candidate    ROOT       Candidate    NOUN   root\n",
            ":            punct      Candidate    NOUN   punctuation\n",
            "\n",
            "---\n",
            "\n",
            "Sentence: Yes indeed For several projects I've leveraged cloud services mainly AWS to enhance scalability and reliability I have experience with EC2 for virtual servers S3 for storage and Lambda for serverless functions which was particularly useful for background tasks and automations.\n",
            "\n",
            "Yes          intj       've          AUX    interjection\n",
            "indeed       advmod     've          AUX    adverbial modifier\n",
            "For          prep       've          AUX    prepositional modifier\n",
            "several      amod       projects     NOUN   adjectival modifier\n",
            "projects     pobj       For          ADP    object of preposition\n",
            "I            nsubj      've          AUX    nominal subject\n",
            "'ve          advcl      have         VERB   adverbial clause modifier\n",
            "leveraged    amod       services     NOUN   adjectival modifier\n",
            "cloud        compound   services     NOUN   compound\n",
            "services     dobj       've          AUX    direct object\n",
            "mainly       advmod     AWS          VERB   adverbial modifier\n",
            "AWS          conj       've          AUX    conjunct\n",
            "to           aux        enhance      VERB   auxiliary\n",
            "enhance      xcomp      AWS          VERB   open clausal complement\n",
            "scalability  dobj       enhance      VERB   direct object\n",
            "and          cc         scalability  NOUN   coordinating conjunction\n",
            "reliability  conj       scalability  NOUN   conjunct\n",
            "I            nsubj      have         VERB   nominal subject\n",
            "have         ROOT       have         VERB   root\n",
            "experience   dobj       have         VERB   direct object\n",
            "with         prep       experience   NOUN   prepositional modifier\n",
            "EC2          pobj       with         ADP    object of preposition\n",
            "for          prep       experience   NOUN   prepositional modifier\n",
            "virtual      amod       servers      NOUN   adjectival modifier\n",
            "servers      pobj       for          ADP    object of preposition\n",
            "S3           appos      servers      NOUN   appositional modifier\n",
            "for          prep       S3           PROPN  prepositional modifier\n",
            "storage      pobj       for          ADP    object of preposition\n",
            "and          cc         storage      NOUN   coordinating conjunction\n",
            "Lambda       conj       storage      NOUN   conjunct\n",
            "for          prep       Lambda       PROPN  prepositional modifier\n",
            "serverless   compound   functions    NOUN   compound\n",
            "functions    pobj       for          ADP    object of preposition\n",
            "which        nsubj      was          AUX    nominal subject\n",
            "was          relcl      functions    NOUN   relative clause modifier\n",
            "particularly advmod     useful       ADJ    adverbial modifier\n",
            "useful       acomp      was          AUX    adjectival complement\n",
            "for          prep       useful       ADJ    prepositional modifier\n",
            "background   compound   tasks        NOUN   compound\n",
            "tasks        pobj       for          ADP    object of preposition\n",
            "and          cc         tasks        NOUN   coordinating conjunction\n",
            "automations  conj       tasks        NOUN   conjunct\n",
            ".            punct      have         VERB   punctuation\n",
            "\n",
            "---\n",
            "\n",
            "Sentence: Regarding containerization I've used Docker to create lightweight portable and consistent environments for development testing and deployment facilitating a smooth CI/CD pipeline with Jenkins.\n",
            "\n",
            "Interviewer:\n",
            "\n",
            "Regarding    prep       used         VERB   prepositional modifier\n",
            "containerization pobj       Regarding    VERB   object of preposition\n",
            "I            nsubj      used         VERB   nominal subject\n",
            "'ve          aux        used         VERB   auxiliary\n",
            "used         ROOT       used         VERB   root\n",
            "Docker       dobj       used         VERB   direct object\n",
            "to           aux        create       VERB   auxiliary\n",
            "create       xcomp      used         VERB   open clausal complement\n",
            "lightweight  amod       environments NOUN   adjectival modifier\n",
            "portable     amod       environments NOUN   adjectival modifier\n",
            "and          cc         portable     ADJ    coordinating conjunction\n",
            "consistent   conj       portable     ADJ    conjunct\n",
            "environments dobj       create       VERB   direct object\n",
            "for          prep       environments NOUN   prepositional modifier\n",
            "development  compound   testing      NOUN   compound\n",
            "testing      pobj       for          ADP    object of preposition\n",
            "and          cc         testing      NOUN   coordinating conjunction\n",
            "deployment   conj       testing      NOUN   conjunct\n",
            "facilitating advcl      create       VERB   adverbial clause modifier\n",
            "a            det        pipeline     NOUN   determiner\n",
            "smooth       amod       pipeline     NOUN   adjectival modifier\n",
            "CI           nmod       CD           NOUN   modifier of nominal\n",
            "/            punct      CD           NOUN   punctuation\n",
            "CD           compound   pipeline     NOUN   compound\n",
            "pipeline     dobj       facilitating VERB   direct object\n",
            "with         prep       facilitating VERB   prepositional modifier\n",
            "Jenkins      pobj       with         ADP    object of preposition\n",
            ".            punct      used         VERB   punctuation\n",
            "\n",
            "\n",
            "           dep        .            PUNCT  unclassified dependent\n",
            "Interviewer  dobj       used         VERB   direct object\n",
            ":            punct      used         VERB   punctuation\n",
            "\n",
            "---\n",
            "\n",
            "Sentence: And how do you keep up with the rapidly changing technology landscape?\n",
            "\n",
            "Candidate: I'm a firm believer in continuous learning I regularly attend tech meetups participate in online forums and take courses on platforms like Coursera and Udemy\n",
            "\n",
            "And          cc         keep         VERB   coordinating conjunction\n",
            "how          advmod     keep         VERB   adverbial modifier\n",
            "do           aux        keep         VERB   auxiliary\n",
            "you          nsubj      keep         VERB   nominal subject\n",
            "keep         ROOT       keep         VERB   root\n",
            "up           prt        keep         VERB   particle\n",
            "with         prep       keep         VERB   prepositional modifier\n",
            "the          det        landscape    NOUN   determiner\n",
            "rapidly      advmod     changing     VERB   adverbial modifier\n",
            "changing     amod       landscape    NOUN   adjectival modifier\n",
            "technology   compound   landscape    NOUN   compound\n",
            "landscape    pobj       with         ADP    object of preposition\n",
            "?            punct      keep         VERB   punctuation\n",
            "\n",
            "\n",
            "           dep        ?            PUNCT  unclassified dependent\n",
            "Candidate    dobj       keep         VERB   direct object\n",
            ":            punct      Candidate    PROPN  punctuation\n",
            "I            nsubj      'm           AUX    nominal subject\n",
            "'m           ccomp      keep         VERB   clausal complement\n",
            "a            det        believer     NOUN   determiner\n",
            "firm         amod       believer     NOUN   adjectival modifier\n",
            "believer     attr       'm           AUX    attribute\n",
            "in           prep       believer     NOUN   prepositional modifier\n",
            "continuous   amod       learning     NOUN   adjectival modifier\n",
            "learning     pobj       in           ADP    object of preposition\n",
            "I            nsubj      attend       VERB   nominal subject\n",
            "regularly    advmod     attend       VERB   adverbial modifier\n",
            "attend       relcl      believer     NOUN   relative clause modifier\n",
            "tech         compound   meetups      NOUN   compound\n",
            "meetups      dobj       attend       VERB   direct object\n",
            "participate  conj       attend       VERB   conjunct\n",
            "in           prep       participate  VERB   prepositional modifier\n",
            "online       amod       forums       NOUN   adjectival modifier\n",
            "forums       pobj       in           ADP    object of preposition\n",
            "and          cc         attend       VERB   coordinating conjunction\n",
            "take         conj       attend       VERB   conjunct\n",
            "courses      dobj       take         VERB   direct object\n",
            "on           prep       take         VERB   prepositional modifier\n",
            "platforms    pobj       on           ADP    object of preposition\n",
            "like         prep       platforms    NOUN   prepositional modifier\n",
            "Coursera     pobj       like         ADP    object of preposition\n",
            "and          cc         Coursera     PROPN  coordinating conjunction\n",
            "Udemy        conj       Coursera     PROPN  conjunct\n",
            "\n",
            "---\n",
            "\n",
            "Sentence: Recently I've been diving into machine learning and AI understanding their potential applications in web development especially in personalized user experiences and predictive analytics.\n",
            "\n",
            "\n",
            "\n",
            "Recently     advmod     been         AUX    adverbial modifier\n",
            "I            nsubj      been         AUX    nominal subject\n",
            "'ve          aux        been         AUX    auxiliary\n",
            "been         aux        diving       ADJ    auxiliary\n",
            "diving       ROOT       diving       ADJ    root\n",
            "into         prep       diving       ADJ    prepositional modifier\n",
            "machine      compound   learning     NOUN   compound\n",
            "learning     pobj       into         ADP    object of preposition\n",
            "and          cc         learning     NOUN   coordinating conjunction\n",
            "AI           conj       learning     NOUN   conjunct\n",
            "understanding advcl      diving       ADJ    adverbial clause modifier\n",
            "their        poss       applications NOUN   possession modifier\n",
            "potential    amod       applications NOUN   adjectival modifier\n",
            "applications dobj       understanding VERB   direct object\n",
            "in           prep       applications NOUN   prepositional modifier\n",
            "web          compound   development  NOUN   compound\n",
            "development  pobj       in           ADP    object of preposition\n",
            "especially   advmod     in           ADP    adverbial modifier\n",
            "in           prep       understanding VERB   prepositional modifier\n",
            "personalized amod       experiences  NOUN   adjectival modifier\n",
            "user         compound   experiences  NOUN   compound\n",
            "experiences  pobj       in           ADP    object of preposition\n",
            "and          cc         experiences  NOUN   coordinating conjunction\n",
            "predictive   amod       analytics    NOUN   adjectival modifier\n",
            "analytics    conj       experiences  NOUN   conjunct\n",
            ".            punct      diving       ADJ    punctuation\n",
            "\n",
            "\n",
            "           dep        .            PUNCT  unclassified dependent\n",
            "\n",
            "---\n",
            "\n",
            "Sentence: Interviewer: Thank you for sharing your experiences with us\n",
            "\n",
            "Interviewer  nsubj      Thank        VERB   nominal subject\n",
            ":            punct      Interviewer  PROPN  punctuation\n",
            "Thank        ROOT       Thank        VERB   root\n",
            "you          dobj       Thank        VERB   direct object\n",
            "for          prep       Thank        VERB   prepositional modifier\n",
            "sharing      pcomp      for          ADP    complement of preposition\n",
            "your         poss       experiences  NOUN   possession modifier\n",
            "experiences  dobj       sharing      VERB   direct object\n",
            "with         prep       sharing      VERB   prepositional modifier\n",
            "us           pobj       with         ADP    object of preposition\n",
            "\n",
            "---\n",
            "\n",
            "Sentence: It's clear you have a strong foundation in software development and a proactive approach to learning and adapting to new technologies\n",
            "\n",
            "It           nsubj      's           AUX    nominal subject\n",
            "'s           ROOT       's           AUX    root\n",
            "clear        acomp      's           AUX    adjectival complement\n",
            "you          nsubj      have         VERB   nominal subject\n",
            "have         ccomp      's           AUX    clausal complement\n",
            "a            det        foundation   NOUN   determiner\n",
            "strong       amod       foundation   NOUN   adjectival modifier\n",
            "foundation   dobj       have         VERB   direct object\n",
            "in           prep       foundation   NOUN   prepositional modifier\n",
            "software     compound   development  NOUN   compound\n",
            "development  pobj       in           ADP    object of preposition\n",
            "and          cc         foundation   NOUN   coordinating conjunction\n",
            "a            det        approach     NOUN   determiner\n",
            "proactive    amod       approach     NOUN   adjectival modifier\n",
            "approach     conj       foundation   NOUN   conjunct\n",
            "to           prep       approach     NOUN   prepositional modifier\n",
            "learning     pcomp      to           ADP    complement of preposition\n",
            "and          cc         learning     VERB   coordinating conjunction\n",
            "adapting     conj       learning     VERB   conjunct\n",
            "to           prep       adapting     VERB   prepositional modifier\n",
            "new          amod       technologies NOUN   adjectival modifier\n",
            "technologies pobj       to           ADP    object of preposition\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def assess_technology_experience(text):\n",
        "    doc = nlp(text)\n",
        "\n",
        "    for sentence in doc.sents:\n",
        "        has_development_verb = False\n",
        "        tech_skills = []\n",
        "\n",
        "        for token in sentence:\n",
        "            # Check for development-related verbs that could indicate hands-on experience\n",
        "            if token.dep_ == \"ROOT\" and token.lemma_ in {\"develop\", \"build\", \"create\", \"implement\", \"use\", \"utilize\"}:\n",
        "                has_development_verb = True\n",
        "\n",
        "            # Check for technologies mentioned as direct objects or objects of prepositions, indicating use in the project\n",
        "            if token.dep_ in {\"dobj\", \"pobj\"} and token.pos_ == \"PROPN\":\n",
        "                tech_skills.append(token.text)\n",
        "\n",
        "        # Assessing the level based on identified patterns\n",
        "        if has_development_verb and tech_skills:\n",
        "            for skill in tech_skills:\n",
        "                print(f\"The candidate has intermediate to advanced experience with {skill} based on the context: '{sentence.text}'\")\n",
        "        elif tech_skills:\n",
        "            for skill in tech_skills:\n",
        "                print(f\"The candidate mentioned {skill}, indicating familiarity: '{sentence.text}'\")\n",
        "\n",
        "# Example usage\n",
        "example_text = \"\"\"Interviewer: Can you tell us about your experience with software development especially in the context of web applications?\n",
        "\n",
        "Candidate: Absolutely I've been involved in software development for over five years now with a particular focus on web applications I've worked extensively with technologies like JavaScript React and Node.js. One of my significant projects was developing a real-time analytics dashboard for a retail client which involved complex data processing and visualization. We used React for the frontend to ensure a responsive and intuitive user interface and Node.js on the backend for its scalability and efficiency with real-time data.\n",
        "\n",
        "Interviewer: That sounds like an impressive project How did you approach the challenges that came with it?\n",
        "\n",
        "Candidate: The project had its set of challenges especially around handling large volumes of data in real-time We utilized WebSocket for real-time data communication between the server and the client For data processing and management we implemented Redis as an in-memory database to reduce latency. The entire development process was agile which allowed us to iterate quickly based on user feedback and continuously improve the application's performance and usability.\n",
        "\n",
        "Interviewer: Have you had experience with cloud technologies or containerization?\n",
        "\n",
        "Candidate: Yes indeed For several projects I've leveraged cloud services mainly AWS to enhance scalability and reliability I have experience with EC2 for virtual servers S3 for storage and Lambda for serverless functions which was particularly useful for background tasks and automations. Regarding containerization I've used Docker to create lightweight portable and consistent environments for development testing and deployment facilitating a smooth CI/CD pipeline with Jenkins.\n",
        "\n",
        "Interviewer: And how do you keep up with the rapidly changing technology landscape?\n",
        "\n",
        "Candidate: I'm a firm believer in continuous learning I regularly attend tech meetups participate in online forums and take courses on platforms like Coursera and Udemy Recently I've been diving into machine learning and AI understanding their potential applications in web development especially in personalized user experiences and predictive analytics.\n",
        "\n",
        "Interviewer: Thank you for sharing your experiences with us It's clear you have a strong foundation in software development and a proactive approach to learning and adapting to new technologies\"\"\"\n",
        "assess_technology_experience(example_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWTSXjOkSjpc",
        "outputId": "38c41ad8-a813-4078-fcfc-c714c6f4b444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The candidate mentioned React, indicating familiarity: 'Absolutely I've been involved in software development for over five years now with a particular focus on web applications I've worked extensively with technologies like JavaScript React and Node.js.'\n",
            "The candidate has intermediate to advanced experience with React based on the context: 'We used React for the frontend to ensure a responsive and intuitive user interface and Node.js on the backend for its scalability and efficiency with real-time data.\n",
            "\n",
            "Interviewer: That sounds like an impressive project How did you approach the challenges that came with it?\n",
            "\n",
            "'\n",
            "The candidate has intermediate to advanced experience with Interviewer based on the context: 'We used React for the frontend to ensure a responsive and intuitive user interface and Node.js on the backend for its scalability and efficiency with real-time data.\n",
            "\n",
            "Interviewer: That sounds like an impressive project How did you approach the challenges that came with it?\n",
            "\n",
            "'\n",
            "The candidate has intermediate to advanced experience with WebSocket based on the context: 'Candidate: The project had its set of challenges especially around handling large volumes of data in real-time We utilized WebSocket for real-time data communication between the server and the client For data processing and management we implemented Redis as an in-memory database to reduce latency.'\n",
            "The candidate has intermediate to advanced experience with Redis based on the context: 'Candidate: The project had its set of challenges especially around handling large volumes of data in real-time We utilized WebSocket for real-time data communication between the server and the client For data processing and management we implemented Redis as an in-memory database to reduce latency.'\n",
            "The candidate mentioned EC2, indicating familiarity: 'Yes indeed For several projects I've leveraged cloud services mainly AWS to enhance scalability and reliability I have experience with EC2 for virtual servers S3 for storage and Lambda for serverless functions which was particularly useful for background tasks and automations.'\n",
            "The candidate has intermediate to advanced experience with Docker based on the context: 'Regarding containerization I've used Docker to create lightweight portable and consistent environments for development testing and deployment facilitating a smooth CI/CD pipeline with Jenkins.\n",
            "\n",
            "Interviewer:'\n",
            "The candidate has intermediate to advanced experience with Jenkins based on the context: 'Regarding containerization I've used Docker to create lightweight portable and consistent environments for development testing and deployment facilitating a smooth CI/CD pipeline with Jenkins.\n",
            "\n",
            "Interviewer:'\n",
            "The candidate has intermediate to advanced experience with Interviewer based on the context: 'Regarding containerization I've used Docker to create lightweight portable and consistent environments for development testing and deployment facilitating a smooth CI/CD pipeline with Jenkins.\n",
            "\n",
            "Interviewer:'\n",
            "The candidate mentioned Candidate, indicating familiarity: 'And how do you keep up with the rapidly changing technology landscape?\n",
            "\n",
            "Candidate: I'm a firm believer in continuous learning I regularly attend tech meetups participate in online forums and take courses on platforms like Coursera and Udemy'\n",
            "The candidate mentioned Coursera, indicating familiarity: 'And how do you keep up with the rapidly changing technology landscape?\n",
            "\n",
            "Candidate: I'm a firm believer in continuous learning I regularly attend tech meetups participate in online forums and take courses on platforms like Coursera and Udemy'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "35BWQv-rfXpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xCjnI0nNgFaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "phlDdq0CgFcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF, TruncatedSVD\n",
        "import numpy as np\n",
        "\n",
        "# Assuming `preprocess_text` returns a list of tokenized, lowercased, and stopwords-removed words for each document\n",
        "processed_docs = preprocess_text(example_text)  # Preprocess your text first\n",
        "\n",
        "# Joining the processed tokens back into document strings\n",
        "docs = [\" \".join(doc) for doc in processed_docs]\n",
        "\n",
        "# Create a TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
        "tfidf = tfidf_vectorizer.fit_transform(docs)\n",
        "\n",
        "# NMF Model\n",
        "nmf_model = NMF(n_components=5, random_state=42)\n",
        "nmf_topic_matrix = nmf_model.fit_transform(tfidf)\n",
        "\n",
        "# LSA (also known as LSI) Model\n",
        "lsa_model = TruncatedSVD(n_components=5, n_iter=100)\n",
        "lsa_topic_matrix = lsa_model.fit_transform(tfidf)\n",
        "\n",
        "# Function to display topics\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(\"Topic %d:\" % (topic_idx+1))\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "no_top_words = 5\n",
        "\n",
        "# Display NMF Topics\n",
        "print(\"NMF Model Topics:\")\n",
        "display_topics(nmf_model, tfidf_vectorizer.get_feature_names_out(), no_top_words)\n",
        "\n",
        "# Display LSA Topics\n",
        "print(\"\\nLSA Model Topics:\")\n",
        "display_topics(lsa_model, tfidf_vectorizer.get_feature_names_out(), no_top_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER4v3SJpgFex",
        "outputId": "fedf3464-0726-4009-ec5a-8d942cab38b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMF Model Topics:\n",
            "Topic 1:\n",
            "learning web applications software development\n",
            "Topic 2:\n",
            "data time real processing client\n",
            "Topic 3:\n",
            "interviewer approach challenges project like\n",
            "Topic 4:\n",
            "cloud experience containerization ve projects\n",
            "Topic 5:\n",
            "user development used containerization ve\n",
            "\n",
            "LSA Model Topics:\n",
            "Topic 1:\n",
            "interviewer development ve software experience\n",
            "Topic 2:\n",
            "data time real client processing\n",
            "Topic 3:\n",
            "interviewer project challenges data approach\n",
            "Topic 4:\n",
            "cloud experience containerization scalability ve\n",
            "Topic 5:\n",
            "user used containerization interviewer development\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "def calculate_ttr(text):\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove punctuation and convert to lower case\n",
        "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Calculate Type-Token Ratio (TTR)\n",
        "    types = set(tokens)\n",
        "    ttr = len(types) / len(tokens) if tokens else 0\n",
        "\n",
        "    return ttr\n",
        "\n",
        "def calculate_sophistication_metrics(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    # Removing punctuation and making lowercase\n",
        "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
        "    # Removing stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if not word in stop_words]\n",
        "\n",
        "    # Number of Tokens\n",
        "    total_tokens = len(tokens)\n",
        "    # Number of Types\n",
        "    total_types = len(set(tokens))\n",
        "    # Calculate TTR\n",
        "    ttr = total_types / total_tokens if total_tokens > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'total_tokens': total_tokens,\n",
        "        'total_types': total_types,\n",
        "        'type_token_ratio': ttr\n",
        "    }\n",
        "\n",
        "# Example Usage\n",
        "interview_text = example_text\n",
        "sophistication_metrics = calculate_sophistication_metrics(interview_text)\n",
        "print(f\"Total Tokens: {sophistication_metrics['total_tokens']}\")\n",
        "print(f\"Total Types: {sophistication_metrics['total_types']}\")\n",
        "print(f\"Type-Token Ratio (TTR): {sophistication_metrics['type_token_ratio']:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7pcWbRugF0R",
        "outputId": "419c1387-fd7e-40a1-ca36-d88637166d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Tokens: 202\n",
            "Total Types: 152\n",
            "Type-Token Ratio (TTR): 0.752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import spacy\n",
        "\n",
        "# Load SpaCy for advanced NLP tasks (if not already loaded)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def analyze_thought_process(text):\n",
        "    # Tokenize the text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "    # Initialize counters and lists\n",
        "    logical_connectors = ['therefore', 'however', 'for example', 'because', 'firstly', 'secondly', 'furthermore', 'moreover']\n",
        "    connector_count = 0\n",
        "    sentence_lengths = []\n",
        "\n",
        "    # Analyze each sentence\n",
        "    for sentence in sentences:\n",
        "        # Tokenize the sentence into words and calculate its length\n",
        "        words = word_tokenize(sentence)\n",
        "        sentence_lengths.append(len(words))\n",
        "        # Count logical connectors\n",
        "        connector_count += sum(1 for word in words if word.lower() in logical_connectors)\n",
        "\n",
        "    # Calculate average sentence length\n",
        "    avg_sentence_length = sum(sentence_lengths) / len(sentence_lengths) if sentence_lengths else 0\n",
        "\n",
        "    return {\n",
        "        'total_sentences': len(sentences),\n",
        "        'average_sentence_length': avg_sentence_length,\n",
        "        'logical_connector_count': connector_count,\n",
        "    }\n",
        "\n",
        "# Example Usage\n",
        "interview_text = example_text\n",
        "thought_process_metrics = analyze_thought_process(interview_text)\n",
        "print(f\"Total Sentences: {thought_process_metrics['total_sentences']}\")\n",
        "print(f\"Average Sentence Length: {thought_process_metrics['average_sentence_length']:.2f}\")\n",
        "print(f\"Logical Connector Count: {thought_process_metrics['logical_connector_count']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPXXR7VoiLlt",
        "outputId": "1d88644c-3a1e-4a1b-9365-8299f62949ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sentences: 13\n",
            "Average Sentence Length: 29.31\n",
            "Logical Connector Count: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def analyze_thought_process(text):\n",
        "    doc = nlp(text)\n",
        "    complex_reasoning_indicators = 0\n",
        "\n",
        "    for sentence in doc.sents:\n",
        "        print(f\"Analyzing Sentence: {sentence.text}\")\n",
        "        for token in sentence:\n",
        "            # Looking for subordinate clauses (marking complex sentences)\n",
        "            if token.dep_ in ['advcl', 'csubj', 'csubjpass']:\n",
        "                print(f\" - Complex reasoning found with '{token.head.text}' due to '{token.text}' ({token.dep_})\")\n",
        "                complex_reasoning_indicators += 1\n",
        "\n",
        "            # Looking for conditional sentences (if-then logic)\n",
        "            if token.dep_ == 'cond':\n",
        "                print(f\" - Conditional logic found with '{token.head.text}' due to '{token.text}' ({token.dep_})\")\n",
        "                complex_reasoning_indicators += 1\n",
        "\n",
        "            # Looking for appositions (additional explanations or details)\n",
        "            if token.dep_ == 'appos':\n",
        "                print(f\" - Detailed explanation found with '{token.head.text}' due to '{token.text}' ({token.dep_})\")\n",
        "                complex_reasoning_indicators += 1\n",
        "\n",
        "    print(f\"Total indicators of complex reasoning: {complex_reasoning_indicators}\")\n",
        "\n",
        "# Example text\n",
        "\n",
        "analyze_thought_process(example_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DGSyNt3jyYE",
        "outputId": "3dcea11b-dc03-4945-bc68-7eed332c3504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing Sentence: Interviewer: Can you tell us about your experience with software development especially in the context of web applications?\n",
            "\n",
            "\n",
            "Analyzing Sentence: Candidate:\n",
            "Analyzing Sentence: Absolutely I've been involved in software development for over five years now with a particular focus on web applications I've worked extensively with technologies like JavaScript React and Node.js.\n",
            "Analyzing Sentence: One of my significant projects was developing a real-time analytics dashboard for a retail client which involved complex data processing and visualization.\n",
            "Analyzing Sentence: We used React for the frontend to ensure a responsive and intuitive user interface and Node.js on the backend for its scalability and efficiency with real-time data.\n",
            "\n",
            "Interviewer: That sounds like an impressive project How did you approach the challenges that came with it?\n",
            "\n",
            "\n",
            "Analyzing Sentence: Candidate: The project had its set of challenges especially around handling large volumes of data in real-time We utilized WebSocket for real-time data communication between the server and the client For data processing and management we implemented Redis as an in-memory database to reduce latency.\n",
            " - Complex reasoning found with 'implemented' due to 'reduce' (advcl)\n",
            "Analyzing Sentence: The entire development process was agile which allowed us to iterate quickly based on user feedback and continuously improve the application's performance and usability.\n",
            "\n",
            "\n",
            " - Complex reasoning found with 'was' due to 'allowed' (advcl)\n",
            "Analyzing Sentence: Interviewer: Have you had experience with cloud technologies or containerization?\n",
            "\n",
            "\n",
            "Analyzing Sentence: Candidate:\n",
            "Analyzing Sentence: Yes indeed For several projects I've leveraged cloud services mainly AWS to enhance scalability and reliability I have experience with EC2 for virtual servers S3 for storage and Lambda for serverless functions which was particularly useful for background tasks and automations.\n",
            " - Complex reasoning found with 'have' due to ''ve' (advcl)\n",
            " - Detailed explanation found with 'servers' due to 'S3' (appos)\n",
            "Analyzing Sentence: Regarding containerization I've used Docker to create lightweight portable and consistent environments for development testing and deployment facilitating a smooth CI/CD pipeline with Jenkins.\n",
            "\n",
            "Interviewer:\n",
            " - Complex reasoning found with 'create' due to 'facilitating' (advcl)\n",
            "Analyzing Sentence: And how do you keep up with the rapidly changing technology landscape?\n",
            "\n",
            "Candidate: I'm a firm believer in continuous learning I regularly attend tech meetups participate in online forums and take courses on platforms like Coursera and Udemy\n",
            "Analyzing Sentence: Recently I've been diving into machine learning and AI understanding their potential applications in web development especially in personalized user experiences and predictive analytics.\n",
            "\n",
            "\n",
            " - Complex reasoning found with 'diving' due to 'understanding' (advcl)\n",
            "Analyzing Sentence: Interviewer: Thank you for sharing your experiences with us\n",
            "Analyzing Sentence: It's clear you have a strong foundation in software development and a proactive approach to learning and adapting to new technologies\n",
            "Total indicators of complex reasoning: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3fNoQm7RkY9J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}